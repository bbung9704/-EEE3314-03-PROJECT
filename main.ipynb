{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ensemble",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dkmqAdtxsxq"
      },
      "source": [
        "#@title\n",
        "### YONSEI Univ. EE, KIM TAEYOON ###\n",
        "import os\n",
        "import PIL\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "import datetime as dt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7JhxgTvyE5s"
      },
      "source": [
        "#@title\n",
        "def load_split_train_test(datadir, img_size=(256, 256), batchsize = 32, valid_size = .2):\n",
        "    train_transforms = transforms.Compose([transforms.Resize(img_size),\n",
        "                                      #  transforms.RandomHorizontalFlip(0.5),\n",
        "                                       transforms.RandomCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       ])\n",
        "    test_transforms = transforms.Compose([transforms.Resize(img_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      ])\n",
        "    train_data = datasets.ImageFolder(datadir,\n",
        "                    transform=train_transforms)\n",
        "    test_data = datasets.ImageFolder(datadir,\n",
        "                    transform=test_transforms)\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    train_idx, test_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(train_data,\n",
        "                   sampler=train_sampler, batch_size=batchsize)\n",
        "    testloader = torch.utils.data.DataLoader(test_data,\n",
        "                   sampler=test_sampler, batch_size=batchsize)\n",
        "    return trainloader, testloader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAaO8u9xyJ9G"
      },
      "source": [
        "#@title\n",
        "\n",
        "class Res(nn.Module):\n",
        "    def __init__(self, num_cls = 3, pretrain=True, finetuning=True):\n",
        "        super().__init__()\n",
        "        self.model = models.resnet50(pretrained=pretrain)\n",
        "        self.finetuning = finetuning\n",
        "        if finetuning == False:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        fc = []\n",
        "        fc += [nn.Linear(self.model.fc.in_features, 512)]\n",
        "        fc += [nn.ReLU()]\n",
        "        fc += [nn.Linear(512, 128)]\n",
        "        fc += [nn.ReLU()]\n",
        "        fc += [nn.Linear(128, num_cls)]\n",
        "        fc += [nn.LogSoftmax(dim=1)]\n",
        "        self.model.fc = nn.Sequential(*fc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model.forward(x)\n",
        "        return out\n",
        "    def get_prams(self):\n",
        "        if self.finetuning:\n",
        "            return list(self.model.parameters()) + list(self.fc.parameters())\n",
        "        else:\n",
        "            return self.model.fc.parameters()\n",
        "\n",
        "class Mobile(nn.Module):\n",
        "    def __init__(self, num_cls = 3, pretrain=True, finetuning=True):\n",
        "        super().__init__()\n",
        "        self.model = models.mobilenet_v2(pretrained=pretrain)\n",
        "        self.finetuning = finetuning\n",
        "        if finetuning == False:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        fc = []\n",
        "        fc += [nn.Linear(1000, 512)]\n",
        "        fc += [nn.ReLU()]\n",
        "        fc += [nn.Linear(512, 128)]\n",
        "        fc += [nn.ReLU()]\n",
        "        fc += [nn.Linear(128, num_cls)]\n",
        "        fc += [nn.LogSoftmax(dim=1)]\n",
        "        self.model.fc = nn.Sequential(*fc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        out = self.model.fc(x)\n",
        "        return out\n",
        "\n",
        "    def get_prams(self):\n",
        "        if self.finetuning:\n",
        "            return list(self.model.parameters()) + list(self.fc.parameters())\n",
        "        else:\n",
        "            return self.model.fc.parameters()\n",
        "\n",
        "class Dense(nn.Module):\n",
        "    def __init__(self, num_cls = 3, pretrain=True, finetuning=True):\n",
        "        super().__init__()\n",
        "        self.model = models.densenet161(pretrained=pretrain)\n",
        "        self.finetuning = finetuning\n",
        "        if finetuning == False:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        fc = []\n",
        "        fc += [nn.Linear(1000, 512)]\n",
        "        fc += [nn.ReLU()]\n",
        "        fc += [nn.Linear(512, 128)]\n",
        "        fc += [nn.ReLU()]\n",
        "        fc += [nn.Linear(128, num_cls)]\n",
        "        fc += [nn.LogSoftmax(dim=1)]\n",
        "        self.model.fc = nn.Sequential(*fc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        out = self.model.fc(x)\n",
        "        # out = self.model.forward(x)\n",
        "        return out\n",
        "    def get_prams(self):\n",
        "        if self.finetuning:\n",
        "            return list(self.model.parameters()) + list(self.fc.parameters())\n",
        "        else:\n",
        "            return self.model.fc.parameters()\n",
        "\n",
        "class Ensemble(nn.Module):\n",
        "    def __init__(self, model1, model2, model3):\n",
        "        super().__init__()\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "        self.model3 = model3\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.model1(x)\n",
        "        out2 = self.model2(x)\n",
        "        out3 = self.model3(x)\n",
        "\n",
        "        out = (out1 + out2 + out3) / 3\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def get_prams(self):\n",
        "        return self.model.parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ff82o1tA3kq"
      },
      "source": [
        "## Functions ##\n",
        "\n",
        "# Train model & Return train_loss, test_loss, test_accuracy, train_accuracy\n",
        "def train(model, iter_n, learningrate):\n",
        "  train_losses, test_losses, test_accuracy, train_accuracy = [], [], [], []\n",
        "  model_opt = torch.optim.Adam(model.get_prams(), lr=learningrate)\n",
        "\n",
        "  for i in range(iter_n):\n",
        "    running_loss = 0\n",
        "    for epoch in range(epochs):\n",
        "      cor_t = 0\n",
        "      lent_t = 0\n",
        "      acc_t = []\n",
        "      for inputs, labels in trainloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          model_opt.zero_grad()\n",
        "          model_out = model(inputs)\n",
        "          model_loss = criterion(model_out, labels)\n",
        "          model_loss.backward()\n",
        "          model_opt.step()\n",
        "          running_loss += model_loss.item()\n",
        "\n",
        "          ps_t = torch.exp(model_out)\n",
        "          top_tp, top_tclass = ps_t.topk(1, dim=1)\n",
        "          equals_t = (top_tclass == labels.view(*top_tclass.shape))\n",
        "          cor_t += torch.sum(equals_t)\n",
        "          lent_t += len(labels)       \n",
        "          acc_t.append(cor_t/lent_t)\n",
        "    \n",
        "    test_loss = 0\n",
        "    cor = 0\n",
        "    lent = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            model_out = model(inputs)\n",
        "            batch_loss = criterion(model_out, labels)\n",
        "            test_loss += batch_loss.item()\n",
        "            ps = torch.exp(model_out)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = (top_class == labels.view(*top_class.shape))\n",
        "            cor += torch.sum(equals)\n",
        "            lent += len(labels)\n",
        "    train_losses.append(running_loss / len(trainloader))\n",
        "    test_losses.append(test_loss / len(testloader))\n",
        "    test_accuracy.append((cor/lent).item())\n",
        "    acc_t = torch.tensor(acc_t)\n",
        "    train_accuracy.append(torch.mean(acc_t).item())\n",
        "    if ((i + 1) % 10 == 0):\n",
        "      print(f\"Iter: {i+1:3d}.. \"\n",
        "            f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "            f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "            f\"Test accuracy: {cor/lent:.3f}.. \"\n",
        "            f\"Train accuracy: {torch.mean(acc_t):.3f}\"\n",
        "            )\n",
        "  return train_losses, test_losses, test_accuracy, train_accuracy\n",
        "\n",
        "# Evaluate model\n",
        "def eval_test(model):\n",
        "  correct = 0\n",
        "  length = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        out = model(inputs)\n",
        "        ps = torch.exp(out)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "\n",
        "        eq = (labels.view(*top_class.shape) == top_class)\n",
        "        correct += torch.sum(eq)\n",
        "        length += (labels.shape[0])\n",
        "        \n",
        "  return correct/length\n",
        "\n",
        "# Plot board\n",
        "def board(train_losses, test_losses, test_accuracy, train_accuracy):\n",
        "  epoch_n = [ x for x in range(len(train_losses))]\n",
        "\n",
        "  plt.style.use(['ggplot'])\n",
        "  fig, ax1 = plt.subplots(figsize=(10,7))\n",
        "\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('loss', color='black')\n",
        "  ax1.plot(epoch_n, train_losses, color='g', label='train loss')\n",
        "  ax1.tick_params(axis='y', labelcolor='black')\n",
        "  ax1.plot(epoch_n, test_losses, color='grey', label='test loss')\n",
        "  plt.legend(loc='lower left')\n",
        "\n",
        "  ax2 = ax1.twinx()\n",
        "  ax2.set_ylabel('accuracy', color='black')\n",
        "  ax2.plot(epoch_n, test_accuracy, color='r', label='test acc')\n",
        "  ax2.tick_params(axis='y', labelcolor='black')\n",
        "  ax2.plot(epoch_n, train_accuracy, color='b', label='train acc')\n",
        "  plt.legend(loc='lower center')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDtsgebJMvKw"
      },
      "source": [
        "### Set Models & Train ###\n",
        "\n",
        "# Config\n",
        "epochs = 1 ## Do not change!\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 10\n",
        "res_train_losses, res_test_losses, res_test_accuracy, res_train_accuracy = [], [], [], []\n",
        "den_train_losses, den_test_losses, den_test_accuracy, den_train_accuracy = [], [], [], []\n",
        "mob_train_losses, mob_test_losses, mob_test_accuracy, mob_train_accuracy = [], [], [], []\n",
        "data_dir = \"/content/drive/MyDrive/project/fashion\" # Your data folder path\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data loader\n",
        "trainloader, testloader = load_split_train_test(data_dir, valid_size=.2)\n",
        "\n",
        "# Networks\n",
        "res = Res(pretrain=True, finetuning=False)\n",
        "res = res.to(device)\n",
        "dense = Dense(pretrain=True, finetuning=False)\n",
        "dense = dense.to(device)\n",
        "mob = Mobile(pretrain=True, finetuning=False)\n",
        "mob = mob.to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Train\n",
        "res_train_losses, res_test_losses, res_test_accuracy, res_train_accuracy = train(res, 100, 0.0001)\n",
        "den_train_losses, den_test_losses, den_test_accuracy, den_train_accuracy = train(dense, 50, 0.0001)\n",
        "mob_train_losses, mob_test_losses, mob_test_accuracy, mob_train_accuracy = train(mob, 50, 0.0001)\n",
        "\n",
        "# Ensemble model\n",
        "ens = Ensemble(res, dense, mob)\n",
        "\n",
        "print(\"----------------------------------------------------------------------------\")\n",
        "print(\"Resnet (eval_test: {:.4f}\".format(eval_test(res)) + \", max_test_acc: {:.4f})\\n\".format(max(res_test_accuracy)))\n",
        "print(\"Densenet (eval_test: {:.4f}\".format(eval_test(dense)) + \", max_test_acc: {:.4f})\\n\".format(max(den_test_accuracy)))\n",
        "print(\"Mobile (eval_test: {:.4f}\".format(eval_test(mob)) + \", max_test_acc: {:.4f})\\n\".format(max(mob_test_accuracy)))\n",
        "print(\"Ensemble test_acc: {:.4f}\".format(eval_test(ens).item()))\n",
        "print(\"----------------------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGxvZKTnPSL7"
      },
      "source": [
        "# Show training process graph\n",
        "\n",
        "board(res_train_losses, res_test_losses, res_test_accuracy, res_train_accuracy)\n",
        "board(den_train_losses, den_test_losses, den_test_accuracy, den_train_accuracy)\n",
        "board(mob_train_losses, mob_test_losses, mob_test_accuracy, mob_train_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKJJx60vgVw-"
      },
      "source": [
        "## Evaluate model & Visualize ##\n",
        "\n",
        "correct = 0\n",
        "length = 0\n",
        "ens.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      out = ens(inputs)\n",
        "      ps = torch.exp(out)\n",
        "      top_p, top_class = ps.topk(1, dim=1)\n",
        "\n",
        "      eq = (labels.view(*top_class.shape) == top_class)\n",
        "      correct += torch.sum(eq)\n",
        "      length += (labels.shape[0])\n",
        "      plt.figure(figsize=(15, 30))\n",
        "\n",
        "      for i in range(len(inputs)):\n",
        "        # {'formal': 0, 'hiphop': 1, 'vintage': 2}\n",
        "        if (top_class[i] == 0):\n",
        "          pred = \"formal\"\n",
        "        elif (top_class[i] == 1):\n",
        "          pred = \"hiphop\"\n",
        "        else:\n",
        "          pred = \"vintage\"\n",
        "        \n",
        "        if (labels[i] == 0):\n",
        "          ans = \"formal\"\n",
        "        elif (labels[i] == 1):\n",
        "          ans = \"hiphop\"\n",
        "        else:\n",
        "          ans = \"vintage\"\n",
        "\n",
        "        img = inputs[i].cpu()\n",
        "        img = img.numpy()\n",
        "        plt.subplot(8, 4, i+1)\n",
        "        if (pred == ans):\n",
        "          plt.title(\"Pred: \" + pred + \"\\nAns: \" + ans, color='black')\n",
        "        else:\n",
        "          plt.title(\"Pred: \" + pred + \"\\nAns: \" + ans, color='red')\n",
        "        plt.axis('off')\n",
        "        plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "      \n",
        "    print(\"Acc: {:.4f}\".format(correct/length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyfXy5gPqmzL"
      },
      "source": [
        "## TSNE Modeling ##\n",
        "# ***CAUTION*** Remove Augmentation: RandomCrop(224)\n",
        " \n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "from plotnine import *\n",
        "\n",
        "first = 1\n",
        "for x_data, y_data in testloader:\n",
        "  if (first == 1):\n",
        "    x = x_data\n",
        "    y = y_data\n",
        "    first = 0\n",
        "  else:  \n",
        "    x = torch.cat((x,x_data), dim=0)\n",
        "    y = torch.cat((y,y_data), dim=0)\n",
        "  \n",
        "for x_data, y_data in trainloader:\n",
        "  x = torch.cat((x,x_data), dim=0)\n",
        "  y = torch.cat((y,y_data), dim=0)\n",
        "\n",
        "\n",
        "x = x.flatten(start_dim=1, end_dim=-1)\n",
        "y = y.unsqueeze(1)\n",
        "t = torch.cat((x,y), dim=1)\n",
        "t = t.numpy()\n",
        "\n",
        "df = pd.DataFrame(t)\n",
        "df.rename(columns = {196608: \"label\"}, inplace=True)\n",
        "\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=10, learning_rate=20, n_iter=1000)\n",
        "tsne_result = tsne.fit_transform(x)\n",
        "\n",
        "df_tsne = df.copy()\n",
        "df_tsne['x-tsne'] = tsne_result[:,0] \n",
        "df_tsne['y-tsne'] = tsne_result[:,1] \n",
        "chart = ggplot( df_tsne, aes(x='x-tsne', y='y-tsne', color='label') ) \\\n",
        "        + geom_point(size=2, alpha=0.6) \\\n",
        "        + ggtitle(\"tSNE dimensions colored by digit\") \n",
        "\n",
        "print(chart)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}